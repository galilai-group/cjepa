# Test/Evaluation Configuration for VideoWM
# This config is used for evaluating a trained world model checkpoint

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null

# Dataset configuration (use validation or test split)
dataset_name: clevrer_train
cache_dir: "/users/hnam16/scratch/.stable_worldmodel"
training_type: video # options: video, wm

# For evaluation 
num_batches: 50


# Checkpoint path - REQUIRED: must exist or evaluation will fail
checkpoint_path: null  # Override with: checkpoint_path=/path/to/model_weights.ckpt

# Model architecture must match training configuration
image_size: 224
patch_size: 16
train_split: 0.8

# Same dinowm configuration as training
dinowm:
  history_size: 3
  num_preds: 1
  proprio_dim: 4
  proprio_embed_dim: 10
  action_dim: 2
  action_embed_dim: 10

predictor:
  depth: 6
  heads: 16
  mlp_dim: 2048
  dim_head: 64
  dropout: 0.1
  emb_dropout: 0.0

# Evaluation parameters
batch_size: 32
num_workers: 8
seed: 42



n_steps:  ${eval:'${dinowm.num_preds} + ${dinowm.history_size}'}
frameskip: 5

# Metrics to compute
metrics:
  rankme:
    enabled: false
    min_batch_size: 512  # Accumulate embeddings across batches
  frechet_joint_distance:
    enabled: true
  feature_rollout_degradation:
    enabled: true
    num_rollout_steps: 5

# Dynamics Visualization (Physics-Inspired Trajectory Analysis)
# These visualizations highlight temporal continuity and interaction events
visualization:
  enabled: false
  
  # 1. Latent Energy Trajectory: 3D PCA with velocity coloring
  # Shows interaction events through rapid latent state changes
  latent_trajectory:
    enabled: true
    # Interpretation: Blue=stable regions, Red=interaction events
    # Requires single-video embeddings (T, D) shape
  
  # 2. Phase Space Plot: State Norm vs Temporal Derivative
  # Visualizes dynamics as attractors and transitions
  phase_space:
    enabled: true
    # Interpretation: Small loops=stable states, Excursions=interactions
  
  # 3. Slot Interaction Dynamics: Multi-object trajectories in latent space
  # Demonstrates object-level dynamics and collision patterns
  slot_interaction:
    enabled: false
    # Note: Requires slot-based representations (unavailable for VideoWM)
  
  # 4. Vector Field of Future Predictions: JEPA-style flow visualization
  # Shows learned dynamics as flow field in latent space
  vector_field:
    enabled: true
    # Interpretation: Laminar=predictable, Turbulent=interactions
  
  # 5. Temporal Self-Similarity Matrix: Block structure reveals phase changes
  # Shows repeated states and interaction-induced partitions
  temporal_similarity:
    enabled: false
    # Interpretation: Diagonal band=continuity, Blocks=phases
  
  # 6. Temporal Distance Matrix: L2 distances over time
  # Alternative view emphasizing state space structure
  temporal_distance:
    enabled: false
    window_size: 1  # Median filter window (1=no smoothing)

# Output
output_dir: "./eval_results"
save_embeddings: false  # Set to true to save all embeddings for analysis
visualization_dir: null  # If null, defaults to output_dir/visualizations

# Videosaur model configuration (for DINO encoder)
videosaur:
  NUM_SLOTS: 7
  SLOT_DIM: 64
  DINO_MODEL: vit_small_patch14_dinov2.lvd142m
  FEAT_DIM: 384
  NUM_PATCHES: 196
  NUM_GPUS: 1
  BATCH_SIZE_PER_GPU: 32
  TOTAL_BATCH_SIZE: "${mul: ${.NUM_GPUS}, ${.BATCH_SIZE_PER_GPU}}"
  BASE_LR: 0.0001
  SIM_WEIGHT: 0.1
  SIM_TEMP: 0.15

# Extended model configuration
model:
  load_weights: null  # Will use pretrained weights automatically
  modules_to_load: None
  input_type: video
  visualize: true
  visualize_every_n_steps: 10000
  target_encoder: null       
  target_encoder_input: null  
  mask_resizers: null
  masks_to_visualize: null

  losses:
    loss_featrec:
      name: MSELoss
      pred_dims:
        - 0
        - ${videosaur.FEAT_DIM}
    loss_timesim:
      name: CrossEntropyLoss
      target_key: encoder.vit_block_keys12
      remove_last_n_frames: 1
      pred_dims:
        - ${videosaur.FEAT_DIM}
        - "${add: ${videosaur.FEAT_DIM}, ${videosaur.NUM_PATCHES}}"
      target_transform:
        name: utils.FeatureTimeSimilarity
        softmax: true
        temperature: ${videosaur.SIM_TEMP}
        threshold: 0.0
  loss_weights:
    loss_timesim: ${videosaur.SIM_WEIGHT}
    loss_featrec: 1.0

  initializer:
    name: RandomInit
    n_slots: ${videosaur.NUM_SLOTS}
    dim: ${videosaur.SLOT_DIM}

  encoder:
    backbone:
      name: TimmExtractor
      model: ${videosaur.DINO_MODEL}
      features:
      - vit_block12
      - vit_block_keys12
      frozen: true
      pretrained: true
    output_transform:
      name: networks.two_layer_mlp
      inp_dim: ${videosaur.FEAT_DIM}
      outp_dim: ${videosaur.SLOT_DIM}
      hidden_dim: "${mul: ${videosaur.FEAT_DIM}, 2}"
      layer_norm: true

  grouper:
    name: SlotAttention
    inp_dim: ${videosaur.SLOT_DIM}
    slot_dim: ${videosaur.SLOT_DIM}
    n_iters: 2
    use_mlp: false

  latent_processor:
    first_step_corrector_args:
      n_iters: 3

  decoder:
    name: SlotMixerDecoder
    inp_dim: ${videosaur.SLOT_DIM}
    embed_dim: ${videosaur.SLOT_DIM}
    outp_dim: "${add: ${videosaur.FEAT_DIM}, ${videosaur.NUM_PATCHES}}"
    n_patches: ${videosaur.NUM_PATCHES}
    allocator:
      name: TransformerEncoder
      dim: ${videosaur.SLOT_DIM}
      memory_dim: ${videosaur.SLOT_DIM}
      n_blocks: 3
      n_heads: 4
    renderer:
      name: MLP
      inp_dim: ${videosaur.SLOT_DIM}
      outp_dim: 1024
      hidden_dims: [1024, 1024]
      final_activation: true
    renderer_dim: 1024
    use_layer_norms: true
    pos_embed_mode: add

  predictor:
    name: networks.TransformerEncoder
    dim: ${videosaur.SLOT_DIM}
    n_blocks: 1
    n_heads: 4

dummy_optimizer:
  name: Adam
  # Scale learning rate by batch size: take base lr once for every 32 samples
  lr: "${eval_dummy: 'a / 32 * b', ${videosaur.TOTAL_BATCH_SIZE}, ${videosaur.BASE_LR}}"
  lr_scheduler:
    name: exp_decay_with_warmup
    warmup_steps: 2000
    decay_steps: ${dummy_trainer.max_steps}

dummy_trainer:
  accelerator: gpu
  max_steps: 100000
  log_every_n_steps: 1
  val_check_interval: 1000
  gradient_clip_val: 0.05