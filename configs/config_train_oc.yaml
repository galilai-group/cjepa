#output_dir: ./outputs

defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled
  # - override hydra/launcher: submitit_slurm

hydra:
  output_subdir: null
  # mode: MULTIRUN
  # launcher:
  #   max_num_timeout: 999
  #   gpus_per_node: 2
  #   tasks_per_node: ${hydra.launcher.gpus_per_node}
  #   cpus_per_task: 4
  #   mem_gb: 48
  #   timeout_min: 4600
  #   partition: main
  #   signal_delay_s: 120
  #   constraint: lovelace
  #   # setup:
  #   # [
  #   #   "tar -czf \"$SLURM_TMPDIR/stablewm.tgz\" -C \"$STABLEWM_HOME\" .",
  #   #   "tar -xzf \"$SLURM_TMPDIR/stablewm.tgz\" -C \"$SLURM_TMPDIR\"",
  #   #   "rm -f \"$SLURM_TMPDIR/stablewm.tgz\""
  #   # ]
  # run:
  #   dir: .

wandb:
  enable: true
  project: cjepa
  entity: heejeong_nam-brown-university

dataset_name: clevrer_train # pusht_expert
cache_dir: "/cs/data/people/hnam16/.stable_worldmodel"
output_model_name: world_model_oc
training_type: video # options: video, wm
# ckpt_dir: "/home/hnam16/.stable_worldmodel"


trainer:
  max_epochs: 100
  strategy: ddp 
  devices: auto
  accelerator: gpu 
  precision: 16-mixed
  log_every_n_steps: 1

batch_size: 64
num_workers: 16
train_split: 0.8
seed: 42

image_size: 224
patch_size: 16

n_steps:  ${eval:'${dinowm.num_preds} + ${dinowm.history_size}'}
frameskip: 5

dinowm:
  history_size: 3
  num_preds: 1
  proprio_dim: 4
  proprio_embed_dim: 10
  action_dim: 2
  action_embed_dim: 10

predictor:
  depth: 6
  heads: 16
  mlp_dim: 2048
  dim_head: 64
  dropout: 0.1
  emb_dropout: 0.0

predictor_lr: 5e-4
proprio_encoder_lr: 5e-4
action_encoder_lr: 5e-4

dump_object: true


videosaur:
  NUM_SLOTS: 7
  SLOT_DIM: 64
  DINO_MODEL: vit_small_patch14_dinov2.lvd142m
  FEAT_DIM: 384
  NUM_PATCHES: 196
  NUM_GPUS: 1
  BATCH_SIZE_PER_GPU: 32
  TOTAL_BATCH_SIZE: "${mul: ${.NUM_GPUS}, ${.BATCH_SIZE_PER_GPU}}"
  BASE_LR: 0.0001
  SIM_WEIGHT: 0.1
  SIM_TEMP: 0.15

model:
  load_weights: "/cs/data/people/hnam16/.stable_worldmodel/artifacts/oc-checkpoints/oc_ckpt.ckpt"
  modules_to_load: None
  input_type: video
  visualize: true
  visualize_every_n_steps: 10000
  target_encoder: null       
  target_encoder_input: null  
  mask_resizers: null
  masks_to_visualize: null

  losses:
    loss_featrec:
      name: MSELoss
      pred_dims:
        - 0
        - ${videosaur.FEAT_DIM}
    loss_timesim:
      name: CrossEntropyLoss
      target_key: encoder.vit_block_keys12
      remove_last_n_frames: 1
      pred_dims:
        - ${videosaur.FEAT_DIM}
        - "${add: ${videosaur.FEAT_DIM}, ${videosaur.NUM_PATCHES}}"
      target_transform:
        name: utils.FeatureTimeSimilarity
        softmax: true
        temperature: ${videosaur.SIM_TEMP}
        threshold: 0.0
  loss_weights:
    loss_timesim: ${videosaur.SIM_WEIGHT}
    loss_featrec: 1.0

  initializer:
    name: RandomInit
    n_slots: ${videosaur.NUM_SLOTS}
    dim: ${videosaur.SLOT_DIM}

  encoder:
    backbone:
      name: TimmExtractor
      model: ${videosaur.DINO_MODEL}
      features:
      - vit_block12
      - vit_block_keys12
      frozen: true
      pretrained: true
    output_transform:
      name: networks.two_layer_mlp
      inp_dim: ${videosaur.FEAT_DIM}
      outp_dim: ${videosaur.SLOT_DIM}
      hidden_dim: "${mul: ${videosaur.FEAT_DIM}, 2}"
      layer_norm: true

  grouper:
    name: SlotAttention
    inp_dim: ${videosaur.SLOT_DIM}
    slot_dim: ${videosaur.SLOT_DIM}
    n_iters: 2
    use_mlp: false

  latent_processor:
    first_step_corrector_args:
      n_iters: 3

  decoder:
    name: SlotMixerDecoder
    inp_dim: ${videosaur.SLOT_DIM}
    embed_dim: ${videosaur.SLOT_DIM}
    outp_dim: "${add: ${videosaur.FEAT_DIM}, ${videosaur.NUM_PATCHES}}"
    n_patches: ${videosaur.NUM_PATCHES}
    allocator:
      name: TransformerEncoder
      dim: ${videosaur.SLOT_DIM}
      memory_dim: ${videosaur.SLOT_DIM}
      n_blocks: 3
      n_heads: 4
    renderer:
      name: MLP
      inp_dim: ${videosaur.SLOT_DIM}
      outp_dim: 1024
      hidden_dims: [1024, 1024]
      final_activation: true
    renderer_dim: 1024
    use_layer_norms: true
    pos_embed_mode: add

  predictor:
    name: networks.TransformerEncoder
    dim: ${videosaur.SLOT_DIM}
    n_blocks: 1
    n_heads: 4

dummy_optimizer:
  name: Adam
  # Scale learning rate by batch size: take base lr once for every 32 samples
  lr: "${eval_dummy: 'a / 32 * b', ${videosaur.TOTAL_BATCH_SIZE}, ${videosaur.BASE_LR}}"
  lr_scheduler:
    name: exp_decay_with_warmup
    warmup_steps: 2000
    decay_steps: ${dummy_trainer.max_steps}

dummy_trainer:
  accelerator: gpu
  max_steps: 100000
  log_every_n_steps: 1
  val_check_interval: 1000
  gradient_clip_val: 0.05
